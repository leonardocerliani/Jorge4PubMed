{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "oPvBGC9p9ABo",
        "9NyDjCWLJo4w",
        "ikMPr6RRDSQV",
        "FumWbbgpDP-O",
        "qQHWlcMXDH6v",
        "18JmOXSDDrD2",
        "fmWzyZU4IkoQ",
        "gwLAsZaSPf8N",
        "2bwa23GuP3Gt",
        "ELdGxi5eRzGm",
        "yCm030e6SA85",
        "BsCkp8cdCgVv"
      ],
      "authorship_tag": "ABX9TyMKqt0JaxQv2bPPttjEgoU3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leonardocerliani/Jorge4PubMed/blob/main/create_citations_db.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Jorge4PubMed companion notebook\n",
        "\n",
        "**NB: this notebook is meant to be run with a [local python kernel/runtime](https://research.google.com/colaboratory/local-runtimes.html)**.\n",
        "\n",
        "If you want to use the Colab runtime, you will need to modify the code below so that it operates on an `md_out` folder hosted on the mounted Google Drive.\n",
        "\n",
        "[GitHub repo](https://github.com/leonardocerliani/Jorge4PubMed)\n",
        "\n",
        "![](https://raw.githubusercontent.com/leonardocerliani/Jorge4PubMed/refs/heads/main/imgs/jorge.png)"
      ],
      "metadata": {
        "id": "Bd7UJUBRbQwj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uvr7apuV_vfZ"
      },
      "outputs": [],
      "source": [
        "# Filename for the db of citations db\n",
        "# (contains filename, title, PMID, full_citation, weblink)\n",
        "db_filename = \"citations.db\"\n",
        "logfile = \"log_citation_db_creation.log\"\n",
        "\n",
        "# Set your email here to use NCBI Entrez API\n",
        "email_for_entrez_service = \"my_email@gmail.com\"\n",
        "limit_esearch_per_second = 3 # Use n > 3 ONLY if you have a PubMed api key\n",
        "\n",
        "# Location of the markdown files extracted from the papers' pdf\n",
        "md_folder = 'md_out'\n",
        "n_lines = 20\n",
        "\n",
        "\n",
        "# Batch size for extracting title using gpt-4o\n",
        "llm_extract_titles_batch_size = 10\n",
        "\n",
        "\n",
        "# Set interactive to True if you want to manually run one cell at the time to\n",
        "# to inspect the process. Set to False if you just want to run the main()\n",
        "# at the end of the notebook.\n",
        "interactive_mode = True\n",
        "\n",
        "# ---------------- MODIFY THE CODE BELOW AT YOUR OWN RISK ----------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions\n"
      ],
      "metadata": {
        "id": "VsQJ2Pz9Fmlw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries"
      ],
      "metadata": {
        "id": "oPvBGC9p9ABo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import os\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "import concurrent.futures\n",
        "from IPython.display import display\n",
        "\n",
        "from Bio import Entrez\n",
        "Entrez.email = email_for_entrez_service\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(filename=logfile, level=logging.INFO, format='%(asctime)s - %(message)s')\n",
        "\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "yJYF2j6fAOoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cosine similarity to verify titles"
      ],
      "metadata": {
        "id": "9NyDjCWLJo4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Cosine similarity between to sentences\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "def batch_sentence_similarity(list1, list2):\n",
        "    assert len(list1) == len(list2), \"Lists must be of equal length\"\n",
        "    embeddings1 = model.encode(list1)\n",
        "    embeddings2 = model.encode(list2)\n",
        "    similarities = np.array([\n",
        "        cosine_similarity([emb1], [emb2])[0][0]\n",
        "        for emb1, emb2 in zip(embeddings1, embeddings2)\n",
        "    ])\n",
        "    return similarities\n",
        "\n",
        "\n",
        "# # Example usage\n",
        "# list1 = [\"The dog sat on the mat.\",\"A quick brown fox jumps over the lazy dog.\",\"I love machine learning.\",\"The weather is nice today.\"]\n",
        "# list2 = [\"There is a cat on the mat.\",\"The fox jumped over a lazy dog quickly.\",\"Machine learning is amazing.\",\"It's a beautiful day outside.\"]\n",
        "\n",
        "# similarities = batch_sentence_similarity(list1,list2)\n",
        "# similarities\n"
      ],
      "metadata": {
        "id": "96kcB4N8Aioo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create citations.db and open the connection"
      ],
      "metadata": {
        "id": "ikMPr6RRDSQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create citations.db if not already existing\n",
        "def create_citations_db_if_not_existing(conn):\n",
        "    cursor = conn.cursor()\n",
        "    print(f\"Database '{db_filename}' loaded or created successfully.\")\n",
        "\n",
        "    cursor.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS citations (\n",
        "        title TEXT,\n",
        "        PMID TEXT,\n",
        "        filename TEXT,\n",
        "        full_citation TEXT,\n",
        "        weblink TEXT,\n",
        "        Pubmed_title TEXT\n",
        "    )\n",
        "    \"\"\")\n",
        "    pprint(cursor.execute(\"PRAGMA table_info(citations)\").fetchall())\n",
        "\n",
        "\n",
        "if interactive_mode:\n",
        "  conn = sqlite3.connect(db_filename)\n",
        "  create_citations_db_if_not_existing(conn)"
      ],
      "metadata": {
        "id": "Hh3-XqhpCBSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get new papers filename"
      ],
      "metadata": {
        "id": "FumWbbgpDP-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get new papers filename\n",
        "def get_new_papers_filename(md_folder, n_lines, conn):\n",
        "    new_papers = []\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    cursor.execute(\"SELECT filename FROM citations\")\n",
        "    existing_filenames = [row[0] for row in cursor.fetchall()]\n",
        "\n",
        "    # Log duplicated filenames found in md_folder that already exist in DB\n",
        "    for filename in os.listdir(md_folder):\n",
        "        if filename.endswith('.md'):\n",
        "            if filename in existing_filenames:\n",
        "                logging.warning(f\"Duplicate filename detected: '{filename}' already exists in the database.\")\n",
        "\n",
        "    print(f\"Scanning folder '{md_folder}' for new markdown files...\")\n",
        "\n",
        "    for filename in os.listdir(md_folder):\n",
        "        if filename.endswith('.md'):\n",
        "            path = os.path.join(md_folder, filename)\n",
        "\n",
        "            with open(path, 'r', encoding='utf-8') as f:\n",
        "                lines = []\n",
        "                for _ in range(n_lines):\n",
        "                    try:\n",
        "                        lines.append(next(f).strip())\n",
        "                    except StopIteration:\n",
        "                        break\n",
        "                multiline_string = \"\\n\".join(lines)\n",
        "\n",
        "            if filename not in existing_filenames:\n",
        "                new_papers.append({\n",
        "                    \"title\": None,\n",
        "                    \"PMID\": None,\n",
        "                    \"filename\": filename,\n",
        "                    \"first_lines\": multiline_string\n",
        "                })\n",
        "\n",
        "    print(f\"Found {len(new_papers)} new markdown files to process.\")\n",
        "    return new_papers\n",
        "\n",
        "# Usage\n",
        "if interactive_mode:\n",
        "  new_papers = get_new_papers_filename(md_folder, n_lines, conn)"
      ],
      "metadata": {
        "id": "zPUsR3N3CUKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract titles from the md using gpt-4.1-nano"
      ],
      "metadata": {
        "id": "qQHWlcMXDH6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Extract titles from the md using gpt-4.1-nano\n",
        "def extract_one_title(content):\n",
        "    extract_title_parsing_instructions = \"\"\"\n",
        "    The following are the first lines of a scientific paper in markdown format.\n",
        "    You task is to extract the title and return **ONLY** the title and nothing else.\n",
        "\n",
        "    - Ignore any markdown formatting, headings, or special characters (e.g., `#`, `**`, etc.).\n",
        "    - Try to correct spelling mistakes for common english words.\n",
        "    - Do not correct anything in technical terms.\n",
        "\n",
        "    It might be helpful to know that:\n",
        "    - the very first line can be a collection heading (e.g. \"Opinions\", \"Original Research\", \"Review paper\", \"Sort Communication\") instead of the title.\n",
        "    - the title is usually just before the author's list\n",
        "    \"\"\"\n",
        "\n",
        "    response = client.responses.create(\n",
        "        model='gpt-4.1-nano',\n",
        "        input=content,\n",
        "        instructions=extract_title_parsing_instructions,\n",
        "        temperature=0.3\n",
        "    )\n",
        "    return response.output_text\n",
        "\n",
        "\n",
        "def llm_extract_titles(new_papers, batch_size=llm_extract_titles_batch_size):\n",
        "    total = len(new_papers)\n",
        "    print(f\"Extracting titles from {total} papers using GPT-4.1-nano in batches of {batch_size}...\")\n",
        "\n",
        "    for i in range(0, total, batch_size):\n",
        "        batch = new_papers[i:i + batch_size]\n",
        "        contents = [paper[\"first_lines\"] for paper in batch]\n",
        "\n",
        "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "            results = list(executor.map(extract_one_title, contents))\n",
        "\n",
        "        for paper, title in zip(batch, results):\n",
        "            paper[\"title\"] = title\n",
        "            del paper[\"first_lines\"]\n",
        "\n",
        "        print(f\"Processed titles for papers {i+1} to {min(i+batch_size, total)} / {total}\")\n",
        "\n",
        "\n",
        "def log_duplicate_titles(new_papers, conn):\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT title, filename FROM citations WHERE title IS NOT NULL\")\n",
        "    existing_records = cursor.fetchall()\n",
        "\n",
        "    existing_titles = {}\n",
        "    for title, filename in existing_records:\n",
        "        if title in existing_titles:\n",
        "            existing_titles[title].append(filename)\n",
        "        else:\n",
        "            existing_titles[title] = [filename]\n",
        "\n",
        "    for paper in new_papers:\n",
        "        title = paper['title']\n",
        "        if title in existing_titles:\n",
        "            existing_files = ', '.join(existing_titles[title])\n",
        "            logging.warning(f\"Duplicate title found: '{title}' from file '{paper['filename']}' matches existing files: {existing_files}\")\n",
        "\n",
        "\n",
        "if interactive_mode:\n",
        "  llm_extract_titles(new_papers, batch_size=10)\n",
        "  log_duplicate_titles(new_papers, conn)\n",
        "  display(pd.DataFrame(new_papers))"
      ],
      "metadata": {
        "id": "M7vYIE-HDD4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial esearch of PMID on Pubmed with lenient proximity (e.g. proximity = 2)"
      ],
      "metadata": {
        "id": "18JmOXSDDrD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Initial search of PMID on Pubmed esearch\n",
        "def fetch_PMIDs_with_rate_limit(new_papers, proximity=2, limit_esearch_per_second=3):\n",
        "    total = len(new_papers)\n",
        "    processed = 0\n",
        "\n",
        "    for paper in new_papers:\n",
        "        title = paper[\"title\"]\n",
        "        try:\n",
        "            handle = Entrez.esearch(db=\"pubmed\", term=f'\"{title}\"[Title:~{proximity}]', retmax=1)\n",
        "            record = Entrez.read(handle)\n",
        "            handle.close()\n",
        "            id_list = record.get(\"IdList\")\n",
        "            paper[\"PMID\"] = id_list[0] if id_list else ''\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error fetching PMID for title '{title}': {e}\")\n",
        "            paper[\"PMID\"] = ''\n",
        "\n",
        "        processed += 1\n",
        "        print(f\"Fetched PMID for {processed}/{total} papers\", end=\"\\r\", flush=True)\n",
        "\n",
        "        if processed % limit_esearch_per_second == 0:\n",
        "            time.sleep(1)\n",
        "\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "if interactive_mode:\n",
        "    proximity_initial_search = 2\n",
        "    limit_esearch_per_second = 3 # Use n > 3 ONLY if you have a PubMed api key\n",
        "\n",
        "    fetch_PMIDs_with_rate_limit(\n",
        "        new_papers,\n",
        "        proximity = proximity_initial_search,\n",
        "        limit_esearch_per_second = limit_esearch_per_second\n",
        "    )\n",
        "\n",
        "    display(pd.DataFrame(new_papers).style)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F4rfm7OtDy8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the title corresponding to the found PMID and store it in a new key `Pubmed_title`"
      ],
      "metadata": {
        "id": "fmWzyZU4IkoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Get the titles of the identified PMIDs using efetch\n",
        "def get_pubmed_titles(new_papers, batch_size=100):\n",
        "    papers_with_pmid = [paper for paper in new_papers if paper.get('PMID')]\n",
        "    if not papers_with_pmid:\n",
        "        print(\"No papers with PMIDs found for validation.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Fetching Pubmed titles for {len(papers_with_pmid)} papers...\")\n",
        "\n",
        "    for i in range(0, len(papers_with_pmid), batch_size):\n",
        "        batch = papers_with_pmid[i:i + batch_size]\n",
        "        pmids_string = \",\".join([p['PMID'] for p in batch])\n",
        "\n",
        "        try:\n",
        "            handle = Entrez.efetch(db=\"pubmed\", id=pmids_string, retmode=\"xml\")\n",
        "            records = Entrez.read(handle)\n",
        "            handle.close()\n",
        "\n",
        "            for paper, article in zip(batch, records['PubmedArticle']):\n",
        "                try:\n",
        "                    fetched_title = article['MedlineCitation']['Article']['ArticleTitle']\n",
        "                    paper['Pubmed_title'] = fetched_title  # Just store the title\n",
        "                except Exception as e:\n",
        "                    logging.error(f\"Error fetching title for PMID {paper.get('PMID')}: {e}\")\n",
        "                    paper['Pubmed_title'] = ''\n",
        "\n",
        "            print(f\"Fetched Pubmed titles for papers {i+1} to {min(i+batch_size, len(papers_with_pmid))}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Entrez fetch error for batch starting at index {i}: {e}\")\n",
        "\n",
        "        print(\"Sleeping for 2 seconds to comply with Pubmed rate limit\")\n",
        "        time.sleep(2)\n",
        "\n",
        "\n",
        "\n",
        "if interactive_mode:\n",
        "  get_pubmed_titles(new_papers)\n",
        "  display(pd.DataFrame(new_papers))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "AatYGc9fGl57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## # Reject PMID where the similarity of title with Pubmed_title is < 0.94"
      ],
      "metadata": {
        "id": "gwLAsZaSPf8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# # Reject PMID where the similarity of title with Pubmed_title is < 0.94\n",
        "# similarity_threshold_initial_search = 0.94\n",
        "\n",
        "def compare_titles_embeddings(new_papers,similarity_threshold):\n",
        "    # Filter papers where Pubmed_title exists and is non-empty\n",
        "    filtered = [p for p in new_papers if p.get('Pubmed_title')]\n",
        "\n",
        "    if not filtered:\n",
        "        print(\"No papers with 'Pubmed_title' to compare.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    titles = [p['title'] for p in filtered]\n",
        "    pubmed_titles = [p['Pubmed_title'] for p in filtered]\n",
        "    pmids = [p['PMID'] for p in filtered]\n",
        "\n",
        "    similarities = batch_sentence_similarity(titles, pubmed_titles)\n",
        "\n",
        "    # Update original papers based on similarity\n",
        "    for paper, sim in zip(filtered, similarities):\n",
        "      if sim < similarity_threshold:\n",
        "          paper['PMID'] = ''\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'title': [p['title'] for p in filtered],\n",
        "        'Pubmed_title': [p.get('Pubmed_title', '') for p in filtered],\n",
        "        'cosine_similarity': similarities,\n",
        "        'PMID': [p['PMID'] for p in filtered]\n",
        "    })\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "if interactive_mode:\n",
        "  similarity_threshold_initial_search = 0.94\n",
        "  df = compare_titles_embeddings(\n",
        "      new_papers,\n",
        "      similarity_threshold=similarity_threshold_initial_search\n",
        "  )\n",
        "  df.style\n",
        "  display(pd.DataFrame(new_papers).style)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "V4qy6_zHI_HN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep search of the title using a window_of_words and strict proximity = 0"
      ],
      "metadata": {
        "id": "2bwa23GuP3Gt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep search using window_of_words and proximity\n",
        "def word_window_proximity_search(new_papers, window_of_words_size=5, proximity_deep_search=0, limit_esearch_per_second = 3):\n",
        "    print(f\"Starting word window proximity search for missing PMIDs (window size = {window_of_words_size}, proximity = {proximity_deep_search})...\")\n",
        "\n",
        "    for idx, paper in enumerate(new_papers, 1):\n",
        "        if paper.get(\"PMID\", '') == '':\n",
        "            print(f\"[{idx}/{len(new_papers)}] Searching PMID for: {paper['title']}\")\n",
        "\n",
        "            words = paper['title'].split()\n",
        "            if len(words) < window_of_words_size:\n",
        "                continue\n",
        "\n",
        "            pmid_counts = {}\n",
        "\n",
        "            for i in range(len(words) - window_of_words_size + 1):\n",
        "                window_words = words[i:i+window_of_words_size]\n",
        "                query = f\"\\\"{' '.join(window_words)}\\\"[Title:~{proximity_deep_search}]\"\n",
        "\n",
        "                try:\n",
        "                    handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=1)\n",
        "                    record = Entrez.read(handle)\n",
        "                    handle.close()\n",
        "                except Exception as e:\n",
        "                    print(f\"Error during Entrez search for query '{query}': {e}\")\n",
        "                    continue\n",
        "\n",
        "                id_list = record.get(\"IdList\", [])\n",
        "                if id_list:\n",
        "                    for pmid in id_list:\n",
        "                        pmid_counts[pmid] = pmid_counts.get(pmid, 0) + 1\n",
        "                    print(f\"Attempt {i+1}: Found PMIDs {id_list}\")\n",
        "\n",
        "                # Sleep after every n requests to keep rate limit\n",
        "                # Use n > 3 ONLY if you have a PubMed api key\n",
        "                if (i + 1) % limit_esearch_per_second == 0:\n",
        "                    time.sleep(1)\n",
        "\n",
        "            if pmid_counts:\n",
        "                most_common_pmid = max(pmid_counts, key=pmid_counts.get)\n",
        "                print(f\"Most frequent PMID: {most_common_pmid}\")\n",
        "                paper[\"PMID\"] = most_common_pmid\n",
        "\n",
        "            print(\"Sleeping for 2 seconds to comply with Pubmed rate limit\")\n",
        "            time.sleep(2)\n",
        "\n",
        "    print(\"Completed word window proximity search.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if interactive_mode:\n",
        "    # carry out the window_of_words search\n",
        "    window_of_words_size = 5\n",
        "    proximity_deep_search = 0\n",
        "    limit_esearch_per_second = 3 # Use n > 3 ONLY if you have a PubMed api key\n",
        "\n",
        "    word_window_proximity_search(\n",
        "        new_papers,\n",
        "        window_of_words_size,\n",
        "        proximity_deep_search,\n",
        "        limit_esearch_per_second\n",
        "    )\n",
        "\n",
        "    # add the Pubmed_title\n",
        "    get_pubmed_titles(new_papers)\n",
        "    display(pd.DataFrame(new_papers).style)\n"
      ],
      "metadata": {
        "id": "kGUTjQBCP8W8",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare llm-retrieved title with Pubmed_title with window_of_words similarity after deep title search. Remove PMID if similarity is < 0.94\n"
      ],
      "metadata": {
        "id": "dX2Pz26YRUb6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare llm-retrieved title with Pubmed_title with window_of_words similarity after deep title search.\n",
        "# Remove PMID if similarity is < 0.94\n",
        "def window_compare_titles_embeddings(new_papers, window_size=5, similarity_threshold=0.94):\n",
        "\n",
        "    def get_windows(words, size):\n",
        "        return [words[i:i+size] for i in range(len(words) - size + 1)] if len(words) >= size else []\n",
        "\n",
        "    filtered = [p for p in new_papers if p.get('Pubmed_title')]\n",
        "\n",
        "    if not filtered:\n",
        "        print(\"No papers with 'Pubmed_title' to compare.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    max_sims = []\n",
        "    keep_flags = []\n",
        "    for paper in filtered:\n",
        "        title_words = paper['title'].split()\n",
        "        pubmed_words = paper['Pubmed_title'].split()\n",
        "\n",
        "        if len(title_words) < window_size or len(pubmed_words) < window_size:\n",
        "            max_sim = 0\n",
        "            # paper['PMID'] = ''  # commented out for testing\n",
        "            keep = False\n",
        "        else:\n",
        "            title_windows = get_windows(title_words, window_size)\n",
        "            pubmed_windows = get_windows(pubmed_words, window_size)\n",
        "\n",
        "            similarities = []\n",
        "            n = min(len(title_windows), len(pubmed_windows))\n",
        "            for i in range(n):\n",
        "                title_segment = \" \".join(title_windows[i])\n",
        "                pubmed_segment = \" \".join(pubmed_windows[i])\n",
        "                sim = batch_sentence_similarity([title_segment], [pubmed_segment])[0]\n",
        "                similarities.append(sim)\n",
        "\n",
        "            max_sim = max(similarities) if similarities else 0\n",
        "\n",
        "            # Comment this 'if' for testing with different similarity thresholds\n",
        "            if max_sim < similarity_threshold:\n",
        "                paper['PMID'] = ''\n",
        "\n",
        "            keep = max_sim >= similarity_threshold\n",
        "\n",
        "        max_sims.append(max_sim)\n",
        "        keep_flags.append(keep)\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'title': [p['title'] for p in filtered],\n",
        "        'Pubmed_title': [p.get('Pubmed_title', '') for p in filtered],\n",
        "        'max_window_cosine_similarity': max_sims,\n",
        "        'PMID': [p['PMID'] for p in filtered],\n",
        "        'kept_based_on_threshold': keep_flags\n",
        "    })\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if interactive_mode:\n",
        "  similarity_threshold_deep_search = 0.94\n",
        "  df = window_compare_titles_embeddings(\n",
        "      new_papers, window_size=5, similarity_threshold=similarity_threshold_deep_search\n",
        "  )\n",
        "  # display(pd.DataFrame(new_papers).style)\n",
        "  display(df)\n"
      ],
      "metadata": {
        "id": "qRsryx-jQAel",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add full citation"
      ],
      "metadata": {
        "id": "ELdGxi5eRzGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add full citation\n",
        "def add_full_citation(new_papers, batch_size=400):\n",
        "    papers_with_pmid = [paper for paper in new_papers if paper.get('PMID')]\n",
        "    if not papers_with_pmid:\n",
        "        print(\"No papers with PMIDs found for citation fetching.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Fetching full citations for {len(papers_with_pmid)} papers...\")\n",
        "\n",
        "    for i in range(0, len(papers_with_pmid), batch_size):\n",
        "        batch = papers_with_pmid[i:i + batch_size]\n",
        "        pmids_string = \",\".join([p['PMID'] for p in batch])\n",
        "\n",
        "        try:\n",
        "            handle = Entrez.efetch(db=\"pubmed\", id=pmids_string, retmode=\"xml\")\n",
        "            records = Entrez.read(handle)\n",
        "            handle.close()\n",
        "\n",
        "            for paper, article in zip(batch, records['PubmedArticle']):\n",
        "                try:\n",
        "                    article_data = article['MedlineCitation']['Article']\n",
        "                    journal_info = article_data.get('Journal', {})\n",
        "                    pub_date = journal_info.get('JournalIssue', {}).get('PubDate', {})\n",
        "\n",
        "                    title = article_data.get('ArticleTitle')\n",
        "                    journal = journal_info.get('Title')\n",
        "                    year = pub_date.get('Year')\n",
        "\n",
        "                    authors = article_data.get('AuthorList', [])\n",
        "                    first_author_surname = authors[0].get('LastName') if authors else None\n",
        "\n",
        "                    full_citation = f'{first_author_surname} ({year}). _{title}_ {journal}'\n",
        "\n",
        "                    paper['full_citation'] = full_citation\n",
        "                    paper['weblink'] = f'https://pubmed.ncbi.nlm.nih.gov/{paper[\"PMID\"]}'\n",
        "                    paper['Pubmed_title'] = title\n",
        "                except (KeyError, IndexError, TypeError) as e:\n",
        "                    logging.error(f\"Error processing article for PMID {paper['PMID']}: {e}\")\n",
        "\n",
        "            print(f\"Processed citations for papers {i+1} to {min(i+batch_size, len(papers_with_pmid))}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error during Entrez fetch for PMIDs batch starting at index {i}: {e}\")\n",
        "\n",
        "\n",
        "if interactive_mode:\n",
        "  add_full_citation(new_papers)"
      ],
      "metadata": {
        "id": "MBgtcMxURwPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Insert new papers in the citations.db"
      ],
      "metadata": {
        "id": "yCm030e6SA85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert new papers in the citations.db (in batches of 100)\n",
        "def insert_new_papers(new_papers, conn, batch_size=100):\n",
        "    cursor = conn.cursor()\n",
        "    total = len(new_papers)\n",
        "    print(f\"Ingesting {total} new papers into the database in batches of {batch_size}...\")\n",
        "\n",
        "    for idx, paper in enumerate(new_papers, 1):\n",
        "        try:\n",
        "            title = paper.get('title')\n",
        "            PMID = paper.get('PMID') or None\n",
        "            filename = paper.get('filename')\n",
        "            full_citation = paper.get('full_citation')\n",
        "            weblink = paper.get('weblink')\n",
        "            Pubmed_title = paper.get('Pubmed_title')\n",
        "\n",
        "            cursor.execute('''\n",
        "                INSERT INTO citations (title, PMID, filename, full_citation, weblink, Pubmed_title)\n",
        "                VALUES (?, ?, ?, ?, ?, ?)\n",
        "            ''', (title, PMID, filename, full_citation, weblink, Pubmed_title))\n",
        "\n",
        "            if idx % batch_size == 0 or idx == total:\n",
        "                conn.commit()\n",
        "                print(f\"Committed batch up to paper {idx}/{total}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to insert paper '{filename}': {e}\")\n",
        "            continue\n",
        "\n",
        "\n",
        "if interactive_mode:\n",
        "  insert_new_papers(new_papers, conn)"
      ],
      "metadata": {
        "id": "iZg_th0mSEM8",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "BsCkp8cdCgVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "def main():\n",
        "    print(\"Starting citation ingestion process...\\n\")\n",
        "\n",
        "    conn = None\n",
        "    try:\n",
        "        # Connect to the SQLite database\n",
        "        conn = sqlite3.connect(db_filename)\n",
        "\n",
        "        # Ensure citations table exists\n",
        "        create_citations_db_if_not_existing(conn)\n",
        "\n",
        "        # Extract new papers from markdown files not yet in the DB\n",
        "        new_papers = get_new_papers_filename(md_folder, n_lines, conn)\n",
        "\n",
        "        if not new_papers:\n",
        "            print(\"No new markdown files found. Exiting.\")\n",
        "            return\n",
        "\n",
        "        # Extract titles from the markdown files using an LLM\n",
        "        llm_extract_titles(new_papers, batch_size=10)\n",
        "\n",
        "        # Log any duplicate titles that already exist in the database\n",
        "        log_duplicate_titles(new_papers, conn)\n",
        "\n",
        "\n",
        "        # ---------- Initial PMID search with proximity = 2 --------------------\n",
        "        proximity_initial_search = 2\n",
        "        limit_esearch_per_second = 3 # Use n > 3 ONLY if you have a PubMed api key\n",
        "\n",
        "        fetch_PMIDs_with_rate_limit(\n",
        "            new_papers,\n",
        "            proximity = proximity_initial_search,\n",
        "            limit_esearch_per_second = limit_esearch_per_second\n",
        "        )\n",
        "\n",
        "        # Get the Pubmed_title for the found PMID\n",
        "        get_pubmed_titles(new_papers)\n",
        "\n",
        "\n",
        "        # Verify after INITIAL SEARCH that the similarity between llm-extracted\n",
        "        # and efetch-ed Pubmed_title is > 0.94 otherwise remove PMID\n",
        "        similarity_threshold_initial_search = 0.94\n",
        "\n",
        "        df_initial_search = compare_titles_embeddings(\n",
        "            new_papers,\n",
        "            similarity_threshold=similarity_threshold_initial_search\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "        # ---------- Deep search of PMID with strict proximity -----------------\n",
        "        # Carry out the window_of_words search\n",
        "        window_of_words_size = 5\n",
        "        proximity_deep_search = 0\n",
        "        limit_esearch_per_second = 3 # Use n > 3 ONLY if you have a PubMed api key\n",
        "\n",
        "        word_window_proximity_search(\n",
        "            new_papers,\n",
        "            window_of_words_size,\n",
        "            proximity_deep_search,\n",
        "            limit_esearch_per_second\n",
        "        )\n",
        "\n",
        "\n",
        "        # add the Pubmed_title\n",
        "        get_pubmed_titles(new_papers)\n",
        "\n",
        "\n",
        "        # Verify after DEEP SEARCH that the similarity between llm-extracted\n",
        "        # and efetch-ed Pubmed_title is > 0.94 otherwise remove PMID\n",
        "        similarity_threshold_deep_search = 0.94\n",
        "\n",
        "        df_deep_search = window_compare_titles_embeddings(\n",
        "            new_papers, window_size=5, similarity_threshold=similarity_threshold_deep_search\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Fetch and store full citation details for validated PMIDs\n",
        "        add_full_citation(new_papers)\n",
        "\n",
        "        # Insert the newly processed papers into the citations database\n",
        "        insert_new_papers(new_papers, conn)\n",
        "\n",
        "        print(\"\\nCitation ingestion process completed.\")\n",
        "\n",
        "        # Print summary of inserted records\n",
        "        cursor = conn.cursor()\n",
        "        cursor.execute(\"SELECT COUNT(*) FROM citations\")\n",
        "        total = cursor.fetchone()[0]\n",
        "\n",
        "        cursor.execute(\"SELECT COUNT(*) FROM citations WHERE PMID != ''\")\n",
        "        with_pmid = cursor.fetchone()[0]\n",
        "\n",
        "        without_pmid = total - with_pmid\n",
        "        percentage_with = (with_pmid / total) * 100 if total else 0\n",
        "\n",
        "        print(f\"\\nSummary of inserted records:\")\n",
        "        print(f\"- Total records: {total}\")\n",
        "        print(f\"- With PMID: {with_pmid}\")\n",
        "        print(f\"- Without PMID: {without_pmid}\")\n",
        "        print(f\"- Percentage with PMID: {percentage_with:.2f}%\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "    finally:\n",
        "        if conn:\n",
        "            conn.close()\n",
        "\n",
        "\n",
        "main()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qOYijXOQCfri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Checking the results"
      ],
      "metadata": {
        "id": "P_B0cggyYbRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "db_filename = \"citations.db\"\n",
        "\n",
        "conn = sqlite3.connect(db_filename)\n",
        "df = pd.read_sql_query(\"SELECT * FROM citations\", conn)\n",
        "conn.close()\n",
        "\n",
        "df.style\n",
        "\n",
        "count_no_pmid = df['PMID'].isna().sum()\n",
        "print(f\"Number of records without PMID: {count_no_pmid}\")\n",
        "print(df.count())\n",
        "\n",
        "df\n",
        "df.style\n",
        "# df[df['PMID'].isna()]\n",
        "\n"
      ],
      "metadata": {
        "id": "kIW6Ld2SDCXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quick fix for the api/insertion problem - **HANDLE WITH CARE**\n",
        "\n",
        "When inserting large amount of papers (400+), for some reason one row might be skipped during the insertion of the PubMed title retrieved from the api. This results the llm-retrieved and the api-retrieved titles to be misaligned and provokes disasters when testing their similarity.\n",
        "\n",
        "I still don't know what causes this, but for the moment the best is to just manually delete all the records in citations.db where PMID is None, and then rerun the script to search again for the articles where PMID was not found.\n",
        "\n"
      ],
      "metadata": {
        "id": "qtlN4K-tUH2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import sqlite3\n",
        "\n",
        "# # Path to your database\n",
        "# db_path = 'citations.db'\n",
        "\n",
        "# # Connect to the SQLite database\n",
        "# conn = sqlite3.connect(db_path)\n",
        "# cursor = conn.cursor()\n",
        "\n",
        "# # Delete records where PMID is NULL or an empty string\n",
        "# cursor.execute(\"DELETE FROM citations WHERE PMID IS NULL OR PMID = ''\")\n",
        "\n",
        "# # Commit changes and close the connection\n",
        "# conn.commit()\n",
        "# conn.close()\n",
        "\n",
        "# print(\"Records with NULL or empty PMID removed.\")\n"
      ],
      "metadata": {
        "id": "R4Gg_FzaULUr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}